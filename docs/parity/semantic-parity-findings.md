# Semantic Parity Validation Findings

## Overview

This document captures findings from WP1.5: Semantic Parity Validation, which validates that Rust-written metadata matches Iceberg-Java/Spark expectations **exactly**, not just "is readable".

**Status:** Complete
**Sprint:** WP1.5 (Production Parity Hardening)
**Test File:** `crates/integration_tests/tests/shared_tests/semantic_parity_test.rs`

## Validation Approach

### Test Infrastructure

We use **paired tables** for comparison:
- `parity_*_rust`: Table where Rust performs the operation
- `parity_*_spark`: Table where Spark performs the identical operation

Both tables start with identical initial state, then we compare the resulting metadata structures field-by-field.

### Comparison Categories

| Category | Expectation |
|----------|-------------|
| Core counts (`added-data-files`, `added-records`) | MUST match exactly |
| Operation type | MUST match exactly |
| Total counts (`total-data-files`, `total-records`) | MUST match exactly |
| Size fields (`added-files-size`, `total-files-size`) | May differ (compression) |
| Parent snapshot linkage (presence) | MUST match (Some/None) |
| IDs (`snapshot-id`) | Expected to differ |
| Timestamps (`committed-at`) | Format/precision documented; values differ |

---

## Snapshot Summary Field Validation

### Fields Validated

| Field | Purpose | Rust Source |
|-------|---------|-------------|
| `added-data-files` | Count of new data files | `SnapshotSummaryCollector` |
| `deleted-data-files` | Count of removed data files | `SnapshotSummaryCollector` |
| `added-records` | Count of new rows | `SnapshotSummaryCollector` |
| `deleted-records` | Count of removed rows | `SnapshotSummaryCollector` |
| `added-delete-files` | Count of new delete files | `SnapshotSummaryCollector` |
| `removed-delete-files` | Count of removed delete files | `SnapshotSummaryCollector` |
| `added-position-deletes` | Count of position delete entries | `SnapshotSummaryCollector` |
| `added-equality-deletes` | Count of equality delete entries | `SnapshotSummaryCollector` |
| `removed-files-size` | Size of removed files | `SnapshotSummaryCollector` |
| `total-data-files` | Running total of data files | `update_snapshot_summaries` |
| `total-delete-files` | Running total of delete files | `update_snapshot_summaries` |
| `total-records` | Running total of records | `update_snapshot_summaries` |
| `total-files-size` | Running total of file size | `update_snapshot_summaries` |
| `total-position-deletes` | Running total of position deletes | `update_snapshot_summaries` |
| `total-equality-deletes` | Running total of equality deletes | `update_snapshot_summaries` |
| `changed-partition-count` | Partitions affected | `SnapshotSummaryCollector` |

### Implementation

Summary fields are generated by:
1. `SnapshotSummaryCollector::build()` - Collects per-operation metrics
2. `update_snapshot_summaries()` - Updates running totals from previous snapshot

**Key file:** `crates/iceberg/src/spec/snapshot_summary.rs`

---

## Commit Metadata Consistency

We validate commit metadata fields that are not summary map entries:

| Field | Expectation | Notes |
|-------|-------------|-------|
| Operation | MUST match | Compared via snapshot summary `operation` |
| Parent snapshot presence | MUST match | Snapshot IDs differ per table, but presence should align |
| Timestamp format/precision | Documented | Rust stores epoch ms; Spark returns timestamp strings |

---

## Manifest Entry Structure

### Required Fields

All manifest entries MUST contain:

| Field | Description | Iceberg Spec |
|-------|-------------|--------------|
| `status` | Entry status (0=existing, 1=added, 2=deleted) | Required |
| `snapshot_id` | Snapshot that added this entry | Required |
| `sequence_number` | Sequence number of the commit | V2+ |
| `file_sequence_number` | Sequence number of the file | V2+ |

### Data File Fields

Each data file entry MUST contain:

| Field | Description |
|-------|-------------|
| `content` | File type (0=data, 1=position-deletes, 2=equality-deletes) |
| `file_path` | Path to the data file |
| `file_format` | Format (parquet, orc, avro) |
| `partition` | Partition values |
| `record_count` | Number of records in file |
| `file_size_in_bytes` | Size of file |

Partition values are normalized into JSON maps for comparison:
- Rust: `partition_struct_to_json` uses the manifest's partition type + `Literal::try_into_json`
- Spark: `Row.asDict(recursive=True)` from the `entries` metadata table

Ordering checks compare status/content sequences and partition multisets to flag any drift.

---

## Edge Case Behavior Matrix

### NULL Handling

| Scenario | Expected Behavior | Test |
|----------|-------------------|------|
| DELETE WHERE col IS NULL | Delete rows with NULL | `test_semantic_parity_null_handling` |
| NULL partition values | Should be serialized correctly | `test_semantic_parity_empty_partition_delete` |
| Predicates with NULL comparisons | Three-valued logic | `test_semantic_parity_three_valued_logic` |

### Empty Results

| Scenario | Expected Behavior | Test |
|----------|-------------------|------|
| DELETE that matches nothing | No snapshot OR no-op snapshot | `test_edge_case_empty_delete` |
| Empty result sets | Graceful handling | `test_edge_case_empty_delete` |

### Boundary Values

| Scenario | Status |
|----------|--------|
| Min/max integers | `test_semantic_parity_boundary_values` |
| Empty strings | `test_semantic_parity_boundary_values` |
| Zero-length binary | `test_semantic_parity_zero_length_binary` |

### Empty Partitions

| Scenario | Expected Behavior | Test |
|----------|-------------------|------|
| DELETE removes entire partition | Partition handled consistently | `test_semantic_parity_empty_partition_delete` |

---

## Error Rejection Parity

Status: **Complete** for schema update rejection cases. Parity tests now assert both engines
reject invalid schema changes:

- Adding an existing column (`test_error_rejection_add_existing_column`)
- Renaming a column to an existing name (`test_error_rejection_rename_to_existing_column`)
- Dropping a missing column (`test_error_rejection_drop_missing_column`)
- Renaming a missing column (`test_error_rejection_rename_missing_column`)
- Incompatible type promotion update (`test_error_rejection_incompatible_type_promotion`)

---

## Known Divergences

### Documented Differences

| Field | Difference | Rationale |
|-------|------------|-----------|
| `added-files-size` | May differ slightly | Compression settings, writer options |
| `removed-files-size` | May differ slightly | Compression settings |
| `total-files-size` | May differ slightly | Cumulative size differences |
| `snapshot-id` | Always differs | Snapshot IDs are table-specific |
| `committed-at` | Format differs | Rust uses epoch ms; Spark returns timestamp string |
| Empty DELETE snapshot creation | Rust skips snapshot, Spark creates no-op snapshot | Allowed and asserted: no snapshot or no-op snapshot |

### Investigated Issues

No unexpected divergences observed in baseline runs. Empty DELETE snapshot creation differs (Rust skips, Spark creates a no-op snapshot) and is asserted as an allowed no-op behavior.

---

## Test Results

### DELETE Operation Parity

**Tables:** `parity_delete_rust`, `parity_delete_spark`
**Operation:** `DELETE WHERE value > 300` (deletes 2 rows)

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| operation | delete | delete | Yes | |
| added-delete-files | 1 | 1 | Yes | |
| added-position-deletes | 2 | 2 | Yes | |
| total-data-files | 1 | 1 | Yes | |

### NULL Handling Parity

**Tables:** `parity_null_rust`, `parity_null_spark`
**Operation:** `DELETE WHERE name IS NULL` (deletes 2 rows)

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| operation | delete | delete | Yes | |

### Three-Valued Logic Parity

**Tables:** `parity_three_valued_rust`, `parity_three_valued_spark`
**Operation:** `DELETE WHERE name = 'alpha' OR name <> 'alpha'` (deletes 2 non-null rows)

Rationale: SQL three-valued logic treats NULL comparisons as UNKNOWN, so only non-null rows match.
Parity is enforced in `test_semantic_parity_three_valued_logic`.

### Zero-Length Binary Parity

**Tables:** `parity_binary_rust`, `parity_binary_spark`
**Operation:** `DELETE WHERE payload = CAST('' AS BINARY)` (deletes empty binary row)

Rationale: Iceberg binary values are arbitrary-length; empty binary is valid and should compare by value.
Parity is enforced in `test_semantic_parity_zero_length_binary`.

### UPDATE Operation Parity

**Tables:** `parity_update_rust`, `parity_update_spark`
**Operation:** `UPDATE status='done' WHERE id > 2` (updates 2 rows)

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| operation | overwrite | overwrite | Yes | |
| added-records | 2 | 2 | Yes | |
| deleted-records | - | - | Yes | |
| added-delete-files | 1 | 1 | Yes | |

### MERGE Operation Parity

**Tables:** `parity_merge_rust`, `parity_merge_spark`
**Operation:** Update ids 1/3 and insert id 5

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| operation | overwrite | overwrite | Yes | |
| added-records | 3 | 3 | Yes | |
| deleted-records | - | - | Yes | |
| added-delete-files | 1 | 1 | Yes | |

### COMPACTION Parity

**Tables:** `parity_compact_rust`, `parity_compact_spark`
**Operation:** Binpack compaction / rewrite_data_files

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| operation | replace | replace | Yes | |
| added-data-files | 1 | 1 | Yes | |
| deleted-data-files | 4 | 4 | Yes | |
| removed-files-size | 2532 | 2532 | Yes | Expected size variance |

### EXPIRE SNAPSHOTS Parity

**Tables:** `parity_expire_rust`, `parity_expire_spark`
**Operation:** Expire snapshots (retain last 1)

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| operation | append | append | Yes | |
| total-data-files | 3 | 3 | Yes | |
| total-records | 3 | 3 | Yes | |

### Boundary Values Parity

**Tables:** `parity_boundary_rust`, `parity_boundary_spark`
**Operation:** `DELETE WHERE id = -2147483648 OR name = ''`

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| operation | delete | delete | Yes | |
| deleted-records | - | - | Yes | |

### Empty Partition + Manifest Entry Parity

**Tables:** `parity_partition_rust`, `parity_partition_spark`
**Operation:** `DELETE WHERE category = 'B'` (empties one partition)

Snapshot summary:

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| operation | delete | delete | Yes | |
| changed-partition-count | 1 | 1 | Yes | |

Manifest entry parity:

| Field | Rust | Spark | Match | Notes |
|-------|------|-------|-------|-------|
| entry-count | 3 | 3 | Yes | |
| status-sequence | [1, 2, 1] | [1, 2, 1] | Yes | Ordering check |
| content-sequence | [0, 0, 0] | [0, 0, 0] | Yes | |
| partition-values | {"{\"category\":\"A\"}": 1, "{\"category\":\"B\"}": 1, "{\"category\":null}": 1} | {"{\"category\":\"A\"}": 1, "{\"category\":\"B\"}": 1, "{\"category\":null}": 1} | Yes | JSON map comparison |

### Error Rejection Parity (Schema Evolution)

**Tables:** `parity_schema_rust`, `parity_schema_spark`

Rationale: Iceberg schema evolution forbids adding a column with an existing name or renaming to an existing name.
Parity is enforced in:
- `test_error_rejection_add_existing_column`
- `test_error_rejection_rename_to_existing_column`

---

## How to Run Tests

```bash
# Start the test containers
cd crates/integration_tests/testdata
docker compose -p testdata up -d --wait

# Run semantic parity tests
ICEBERG_SPARK_CONTAINER=testdata-spark-iceberg-1 cargo test --test integration_test semantic_parity -- --nocapture

# Run specific test
ICEBERG_SPARK_CONTAINER=testdata-spark-iceberg-1 cargo test --test integration_test test_semantic_parity_delete -- --nocapture
```

---

## Recommendations

### Completed

1. [x] Added `snapshot_summary` + `execute_sql` validation types to validate.py
2. [x] Added Rust helpers for snapshot summary + manifest entry extraction
3. [x] Created comparison infrastructure in semantic_parity_test.rs
4. [x] Implemented DELETE + NULL handling parity tests
5. [x] Implemented UPDATE, MERGE, COMPACTION, EXPIRE parity tests
6. [x] Implemented boundary value + empty partition parity tests
7. [x] Implemented manifest entry parity comparison (structure + partition serialization)
8. [x] Implemented three-valued logic parity test
9. [x] Implemented zero-length binary parity test
10. [x] Implemented schema update error rejection parity tests
11. [x] Ran tests against live containers to populate findings
12. [x] Enforced strict divergence allowlist assertions in parity tests
13. [x] Added missing-column error rejection parity tests
14. [x] Added incompatible type promotion rejection parity test

### To Do

None.

---

## References

- **Iceberg Spec:** https://iceberg.apache.org/spec/
- **Snapshot Summary fields:** `crates/iceberg/src/spec/snapshot_summary.rs`
- **Manifest structure:** `crates/iceberg/src/spec/manifest/`
- **Test file:** `crates/integration_tests/tests/shared_tests/semantic_parity_test.rs`
